{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "512160eb-0b26-4023-bf95-6d5a1ece5c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>actions</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>location</th>\n",
       "      <th>Type</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10091</td>\n",
       "      <td>It's the everything else that's complicated. #...</td>\n",
       "      <td>0</td>\n",
       "      <td>11500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>NotSpam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10172</td>\n",
       "      <td>Eren sent a glare towards Mikasa then nodded a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NotSpam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7012</td>\n",
       "      <td>I posted a new photo to Facebook http://fb.me/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Scotland, U.K</td>\n",
       "      <td>NotSpam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3697</td>\n",
       "      <td>#jan Idiot Chelsea Handler Diagnoses Trump Wit...</td>\n",
       "      <td>3319</td>\n",
       "      <td>611</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>Atlanta, Ga</td>\n",
       "      <td>Spam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10740</td>\n",
       "      <td>Pedophile Anthony Weiner is TERRIFIED of Getti...</td>\n",
       "      <td>4840</td>\n",
       "      <td>1724</td>\n",
       "      <td>1522</td>\n",
       "      <td>0</td>\n",
       "      <td>Blumberg</td>\n",
       "      <td>Spam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id                                              Tweet following  \\\n",
       "0  10091  It's the everything else that's complicated. #...         0   \n",
       "1  10172  Eren sent a glare towards Mikasa then nodded a...         0   \n",
       "2   7012  I posted a new photo to Facebook http://fb.me/...         0   \n",
       "3   3697  #jan Idiot Chelsea Handler Diagnoses Trump Wit...      3319   \n",
       "4  10740  Pedophile Anthony Weiner is TERRIFIED of Getti...      4840   \n",
       "\n",
       "  followers actions is_retweet       location     Type Unnamed: 8 Unnamed: 9  \\\n",
       "0     11500     NaN          0        Chicago  NotSpam        NaN        NaN   \n",
       "1         0     NaN          0            NaN  NotSpam        NaN        NaN   \n",
       "2         0     NaN          0  Scotland, U.K  NotSpam        NaN        NaN   \n",
       "3       611     294          0    Atlanta, Ga     Spam        NaN        NaN   \n",
       "4      1724    1522          0       Blumberg     Spam        NaN        NaN   \n",
       "\n",
       "  Unnamed: 10 Unnamed: 11  \n",
       "0         NaN         NaN  \n",
       "1         NaN         NaN  \n",
       "2         NaN         NaN  \n",
       "3         NaN         NaN  \n",
       "4         NaN         NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "# Load data from the single CSV file\n",
    "data = pd.read_csv('data/twitter.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c07a821-d214-461b-9ee0-4898d9a7be41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>actions</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>location</th>\n",
       "      <th>Type</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10091</td>\n",
       "      <td>It's the everything else that's complicated. #...</td>\n",
       "      <td>0</td>\n",
       "      <td>11500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>NotSpam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10172</td>\n",
       "      <td>Eren sent a glare towards Mikasa then nodded a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NotSpam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7012</td>\n",
       "      <td>I posted a new photo to Facebook http://fb.me/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Scotland, U.K</td>\n",
       "      <td>NotSpam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3697</td>\n",
       "      <td>#jan Idiot Chelsea Handler Diagnoses Trump Wit...</td>\n",
       "      <td>3319</td>\n",
       "      <td>611</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>Atlanta, Ga</td>\n",
       "      <td>Spam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10740</td>\n",
       "      <td>Pedophile Anthony Weiner is TERRIFIED of Getti...</td>\n",
       "      <td>4840</td>\n",
       "      <td>1724</td>\n",
       "      <td>1522</td>\n",
       "      <td>0</td>\n",
       "      <td>Blumberg</td>\n",
       "      <td>Spam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id                                              Tweet following  \\\n",
       "0  10091  It's the everything else that's complicated. #...         0   \n",
       "1  10172  Eren sent a glare towards Mikasa then nodded a...         0   \n",
       "2   7012  I posted a new photo to Facebook http://fb.me/...         0   \n",
       "3   3697  #jan Idiot Chelsea Handler Diagnoses Trump Wit...      3319   \n",
       "4  10740  Pedophile Anthony Weiner is TERRIFIED of Getti...      4840   \n",
       "\n",
       "  followers actions is_retweet       location     Type Unnamed: 8 Unnamed: 9  \\\n",
       "0     11500     NaN          0        Chicago  NotSpam        NaN        NaN   \n",
       "1         0     NaN          0            NaN  NotSpam        NaN        NaN   \n",
       "2         0     NaN          0  Scotland, U.K  NotSpam        NaN        NaN   \n",
       "3       611     294          0    Atlanta, Ga     Spam        NaN        NaN   \n",
       "4      1724    1522          0       Blumberg     Spam        NaN        NaN   \n",
       "\n",
       "  Unnamed: 10 Unnamed: 11  \n",
       "0         NaN         NaN  \n",
       "1         NaN         NaN  \n",
       "2         NaN         NaN  \n",
       "3         NaN         NaN  \n",
       "4         NaN         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bfb3bbc-b0dd-4f8b-93fb-56fa99b40818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11968 entries, 0 to 11967\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Id           11968 non-null  int64 \n",
      " 1   Tweet        11968 non-null  object\n",
      " 2   following    11826 non-null  object\n",
      " 3   followers    11949 non-null  object\n",
      " 4   actions      9206 non-null   object\n",
      " 5   is_retweet   11958 non-null  object\n",
      " 6   location     10324 non-null  object\n",
      " 7   Type         11958 non-null  object\n",
      " 8   Unnamed: 8   178 non-null    object\n",
      " 9   Unnamed: 9   19 non-null     object\n",
      " 10  Unnamed: 10  4 non-null      object\n",
      " 11  Unnamed: 11  1 non-null      object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "882a8b06-4b13-436d-bc78-9c7b0c2fbbe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's the everything else that's complicated. #...</td>\n",
       "      <td>NotSpam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eren sent a glare towards Mikasa then nodded a...</td>\n",
       "      <td>NotSpam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I posted a new photo to Facebook http://fb.me/...</td>\n",
       "      <td>NotSpam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#jan Idiot Chelsea Handler Diagnoses Trump Wit...</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pedophile Anthony Weiner is TERRIFIED of Getti...</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11963</th>\n",
       "      <td>11:11 meet harry</td>\n",
       "      <td>NotSpam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>If BBC Food disappears the loss of knowledge w...</td>\n",
       "      <td>NotSpam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11965</th>\n",
       "      <td>Look What Liberals Did to This Historic Monume...</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11966</th>\n",
       "      <td>I uploaded a new track, \"Everyday Lite 1\", on ...</td>\n",
       "      <td>NotSpam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11967</th>\n",
       "      <td>Trump should be declared the victor by about 9...</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11788 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet     Type\n",
       "0      It's the everything else that's complicated. #...  NotSpam\n",
       "1      Eren sent a glare towards Mikasa then nodded a...  NotSpam\n",
       "2      I posted a new photo to Facebook http://fb.me/...  NotSpam\n",
       "3      #jan Idiot Chelsea Handler Diagnoses Trump Wit...     Spam\n",
       "4      Pedophile Anthony Weiner is TERRIFIED of Getti...     Spam\n",
       "...                                                  ...      ...\n",
       "11963                                   11:11 meet harry  NotSpam\n",
       "11964  If BBC Food disappears the loss of knowledge w...  NotSpam\n",
       "11965  Look What Liberals Did to This Historic Monume...     Spam\n",
       "11966  I uploaded a new track, \"Everyday Lite 1\", on ...  NotSpam\n",
       "11967  Trump should be declared the victor by about 9...     Spam\n",
       "\n",
       "[11788 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing: Filter columns and clean data as needed\n",
    "# Filter the dataset to include only 'Spam' and 'NotSpam' classes\n",
    "data = data[data['Type'].isin(['Spam', 'NotSpam'])]\n",
    "data = data[['Tweet', 'Type']].dropna()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b91b320f-237c-4f6e-871e-c3f983f66e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I posted a new photo to Facebook http://fb.me/2Be7LiyuJ'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[2,'Tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2e65fbf-cff6-4baa-a9b3-3c6edbd220b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#jan Idiot Chelsea Handler Diagnoses Trump With a Disease https://t.co/k8PrqcWTRI https://t.co/dRN35xtSJZ'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[3,'Tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3136f381-fa65-4b1a-b74a-8d3cc93d65e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'twitterTfidfVectorizer.sav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a TF-IDF vectorizer\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtwitterTfidfVectorizer.sav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m X \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTweet\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32m~\\Downloads\\Spam-Detection-System-Safeguarding-Digital-Spaces-\\env\\Lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'twitterTfidfVectorizer.sav'"
     ]
    }
   ],
   "source": [
    "# Create a TF-IDF vectorizer\n",
    "vectorizer = joblib.load('twitterTfidfVectorizer.sav')\n",
    "X = vectorizer.fit_transform(data['Tweet'].values)\n",
    "y = data['Type'].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a383502-afed-48a2-9b10-65c606d2e493",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "# Check class distribution in the training data\n",
    "class_distribution = pd.Series(y_train).value_counts()\n",
    "print(\"Class Distribution in Training Data:\\n\", class_distribution)\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Oversample the minority class using RandomOverSampler\n",
    "oversampler = RandomOverSampler(sampling_strategy='minority')\n",
    "X_train_over, y_train_over = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train the classifier on the oversampled data\n",
    "rf_classifier.fit(X_train_over, y_train_over)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "\n",
    "# Optionally, you can also use imbalanced-learn's classification report\n",
    "classification_rep_imbalanced = classification_report_imbalanced(y_test, y_pred)\n",
    "print(\"Classification Report (Imbalanced-learn):\\n\", classification_rep_imbalanced)\n",
    "\n",
    "\n",
    "# Plot confusion matrix for Random Forest\n",
    "rf_cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(rf_cm, annot=True, fmt='d', cmap='Blues', xticklabels=[1, 0], yticklabels=[1, 0])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix for Random Forest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d19f67-d48a-4e27-9224-4ee178042c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the SVM classifier\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with SVM\n",
    "svm_predictions = svm.predict(X_test)\n",
    "# Calculate evaluation metrics for SVM with 'macro' average setting\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "svm_precision = precision_score(y_test, svm_predictions, average='macro', zero_division='warn')\n",
    "svm_recall = recall_score(y_test, svm_predictions, average='macro', zero_division='warn')\n",
    "svm_f1 = f1_score(y_test, svm_predictions, average='macro', zero_division='warn')\n",
    "\n",
    "# Print results for SVM\n",
    "print(\"SVM Classifier:\")\n",
    "print(f\"Accuracy: {svm_accuracy}\")\n",
    "print(f\"Precision: {svm_precision}\")\n",
    "print(f\"Recall: {svm_recall}\")\n",
    "print(f\"F1 Score: {svm_f1}\")\n",
    "\n",
    "# Plot confusion matrix for SVM\n",
    "svm_cm = confusion_matrix(y_test, svm_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(svm_cm, annot=True, fmt='d', cmap='Blues', xticklabels=[1, 0], yticklabels=[1, 0])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix for SVM')\n",
    "plt.show()\n",
    "\n",
    "# Save the trained SVM classifier\n",
    "joblib.dump(svm, 'SVCClassifier_model.sav')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cb03c7-98ce-4ff3-a053-572e1e32e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the Naive Bayes classifier\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with Naive Bayes\n",
    "nb_predictions = naive_bayes.predict(X_test)\n",
    "# Calculate evaluation metrics for Naive Bayes with 'macro' average setting\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "nb_precision = precision_score(y_test, nb_predictions, average='macro', zero_division='warn')\n",
    "nb_recall = recall_score(y_test, nb_predictions, average='macro', zero_division='warn')\n",
    "nb_f1 = f1_score(y_test, nb_predictions, average='macro', zero_division='warn')\n",
    "\n",
    "# Print results for Naive Bayes\n",
    "print(\"Naive Bayes Classifier:\")\n",
    "print(f\"Accuracy: {nb_accuracy}\")\n",
    "print(f\"Precision: {nb_precision}\")\n",
    "print(f\"Recall: {nb_recall}\")\n",
    "print(f\"F1 Score: {nb_f1}\")\n",
    "\n",
    "# Save the trained Naive Bayes classifier\n",
    "joblib.dump(naive_bayes, 'MultinomialNB_model.sav')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243b985b-009c-488b-913d-9626437390a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
